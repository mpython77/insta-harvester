# ğŸš€ Instagram Scraper - Professional Edition

Professional Instagram scraper with **automatic** post & reel data extraction, advanced diagnostics, error recovery, and performance monitoring.

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

---

## âœ¨ Features

### ğŸ¯ Core Features
- âœ… **Full Automatic Scraping** - Just enter username, everything else is automatic
- âœ… **Post & Reel Support** - Handles both content types intelligently
- âœ… **Real-time Excel Export** - Live export with Type column (Post/Reel)
- âœ… **Parallel Processing** - 3 concurrent tabs for faster scraping
- âœ… **Smart Type Detection** - Automatically identifies posts vs reels

### ğŸ” Professional Features
- âœ… **HTML Diagnostics** - Detects Instagram HTML changes automatically
- âœ… **Error Recovery** - 90%+ recovery rate with fallback methods
- âœ… **Performance Monitoring** - Real-time CPU, memory, and speed tracking
- âœ… **Memory Optimization** - Automatic garbage collection
- âœ… **Detailed Statistics** - Comprehensive reports after scraping

### ğŸ“Š Data Extraction
- **Posts:** Tags, Likes, Date
- **Reels:** Tags (via popup), Likes, Date
- **Profile:** Posts count, Followers, Following
- **Output:** Excel + JSON with Type column

---

## ğŸš€ Quick Start

### 1ï¸âƒ£ Installation

```bash
# Clone repository
git clone https://github.com/yourusername/ArtemInsta.git
cd ArtemInsta

# Install dependencies
pip install -r requirements.txt

# Install Playwright browsers
playwright install chromium
```

### 2ï¸âƒ£ Setup Instagram Session

```bash
# Run once to save your Instagram session
python save_session.py

# Follow the prompts:
# - Enter username
# - Enter password
# - Complete 2FA if enabled
# Session saved to: instagram_session.json
```

### 3ï¸âƒ£ Run Full Auto Scraping

```bash
# Just run and enter username!
python main_advanced.py

# That's it! ğŸ‰
# Output:
# - instagram_data_USERNAME.xlsx (with Type column)
# - instagram_data_USERNAME.json
# - instagram_scraper_USERNAME.log
```

---

## ğŸ“– Usage

### FULL AUTO MODE (Recommended)

```bash
python main_advanced.py
```

**Input:** Username only!

**What it does:**
1. âœ… Collects ALL post & reel links (Phase 1)
2. âœ… Extracts data from each item (Phase 2)
3. âœ… Saves to Excel with Type column
4. âœ… Shows detailed statistics

**Example:**
```
ğŸš€ INSTAGRAM SCRAPER - PROFESSIONAL FULL AUTO MODE

ğŸ“ Enter Instagram username: cristiano
ğŸ¯ Target: @cristiano

âš™ï¸  Configuration (OPTIMIZED):
   - Parallel: 3 tabs (fast & stable)
   - Excel: Real-time export
   - Diagnostics: Enabled
   - Error Recovery: Enabled
   - Performance Monitoring: Enabled

ğŸš€ Press ENTER to start...

[Automatic scraping starts...]

âœ… FULL AUTOMATIC SCRAPING COMPLETE!

ğŸ“Š RESULTS:
   Username: @cristiano
   Total Posts: 3,567
   Links Collected: 3,567 items
     - Posts: 2,234
     - Reels: 1,333
   Data Extracted: 3,567 items
   Successful: 3,545/3,567 (99.4%)

ğŸ’¾ Output Files:
   ğŸ“Š Excel: instagram_data_cristiano.xlsx
   ğŸ“„ JSON: instagram_data_cristiano.json
   ğŸ“‹ Log: instagram_scraper_cristiano.log
```

---

## ğŸ“Š Output Format

### Excel File Structure

| Post URL | Type | Tagged Accounts | Likes Count | Post Date | Scraping Date/Time |
|----------|------|-----------------|-------------|-----------|-------------------|
| https://... | Post | user1, user2 | 1234 | Nov 17, 2025 | 2025-11-22 10:30:15 |
| https://... | Reel | user3, user4 | 5678 | Nov 18, 2025 | 2025-11-22 10:32:45 |

### JSON File Structure

```json
{
  "username": "cristiano",
  "profile": {
    "posts": 3567,
    "followers": "500M",
    "following": "500"
  },
  "post_links": [
    {"url": "https://...", "type": "Post"},
    {"url": "https://...", "type": "Reel"}
  ],
  "posts_data": [
    {
      "url": "https://...",
      "tagged_accounts": ["user1", "user2"],
      "likes": "1234",
      "timestamp": "Nov 17, 2025",
      "content_type": "Post"
    }
  ]
}
```

---

## ğŸ” Advanced Features

### HTML Diagnostics

Automatically detects when Instagram changes their HTML structure:

```
ğŸ” Running POST diagnostics...
  âœ“ tags_primary: Found 3 elements (0.042s)
  âœ“ likes_button: Found 1 elements (0.031s)
  âœ— timestamp: NOT FOUND (0.028s)

âš ï¸ HTML CHANGE DETECTED: 'timestamp' selector failed!
   Selector: time
   Instagram may have updated HTML structure
```

### Error Recovery

Automatic fallback methods:

```
âš ï¸ likes: Primary method failed - TimeoutError
âœ“ likes: Fallback method succeeded

ERROR STATISTICS:
  Total Errors: 15
  Recovered: 14
  Failed: 1
  Recovery Rate: 93.3%
```

### Performance Monitoring

Real-time monitoring:

```
ğŸ’» SYSTEM INFO:
  CPU: 8 cores @ 15.2%
  RAM: 12.3/16.0 GB available
  Process: 342.15 MB, CPU: 8.3%

â™»ï¸ Memory optimized: Freed 45.23 MB

ğŸ“Š PERFORMANCE REPORT:
  Total Time: 45.32s
  Operations/Second: 0.55
  Peak Memory: 342.15 MB
```

---

## ğŸ§ª Testing & Examples

Check the `examples/` directory for test scripts:

```bash
# Test link collection
python examples/test_phase1.py

# Test data extraction
python examples/test_phase2.py

# Test professional features
python examples/test_professional.py
```

See [examples/README.md](examples/README.md) for detailed documentation.

---

## ğŸ“ Project Structure

```
ArtemInsta/
â”œâ”€â”€ main_advanced.py           # FULL AUTO SCRAPING (main script)
â”œâ”€â”€ save_session.py            # Instagram login session manager
â”œâ”€â”€ requirements.txt           # Python dependencies
â”œâ”€â”€ instagram_scraper/         # Core library
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base.py               # Base scraper class
â”‚   â”œâ”€â”€ config.py             # Configuration
â”‚   â”œâ”€â”€ post_links.py         # Link collection (Phase 1)
â”‚   â”œâ”€â”€ post_data.py          # Data extraction (Phase 2) - PROFESSIONAL
â”‚   â”œâ”€â”€ diagnostics.py        # HTML diagnostics system
â”‚   â”œâ”€â”€ error_handler.py      # Error recovery system
â”‚   â”œâ”€â”€ performance.py        # Performance monitoring
â”‚   â”œâ”€â”€ parallel_scraper.py   # Parallel processing
â”‚   â”œâ”€â”€ excel_export.py       # Real-time Excel export
â”‚   â””â”€â”€ orchestrator.py       # Workflow coordinator
â”œâ”€â”€ examples/                  # Test & example scripts
â”‚   â”œâ”€â”€ README.md
â”‚   â”œâ”€â”€ test_phase1.py        # Link collection test
â”‚   â”œâ”€â”€ test_phase2.py        # Data extraction test
â”‚   â””â”€â”€ test_professional.py  # Professional features test
â””â”€â”€ PROFESSIONAL_FEATURES.md   # Documentation (Uzbek)
```

---

## âš™ï¸ Configuration

### Default Configuration (Optimized)

```python
from instagram_scraper import ScraperConfig

config = ScraperConfig(
    headless=False,           # Visual mode
    log_level='INFO',         # Detailed logs
    log_to_console=True,      # Console output
    parallel=3,               # 3 concurrent tabs
    enable_diagnostics=True,  # HTML diagnostics
)
```

### Headless Mode (Server/Production)

```python
config = ScraperConfig(
    headless=True,  # No browser window
    log_level='INFO',
)
```

---

## ğŸ› ï¸ Requirements

- **Python:** 3.8+
- **OS:** Windows, macOS, Linux
- **RAM:** 4GB+ (8GB recommended for parallel processing)
- **Disk:** 500MB for dependencies

### Dependencies

```
playwright==1.48.0      # Browser automation
beautifulsoup4==4.12.3  # HTML parsing
openpyxl==3.1.2        # Excel export
pandas==2.2.0          # Data manipulation
lxml==5.1.0            # Fast XML/HTML parsing
psutil==5.9.8          # Performance monitoring
```

---

## ğŸ› Troubleshooting

### Session Expired

```bash
# Re-run session setup
python save_session.py
```

### "Profile not found"

- Check username spelling
- Make sure profile is public or you follow it

### Slow Scraping

- Reduce parallel tabs: `parallel=2`
- Check internet speed
- Close other browser tabs

### HTML Structure Changed

The scraper will automatically detect and report HTML changes:

```
âŒ CRITICAL HTML STRUCTURE CHANGE DETECTED!
   Failed selectors: timestamp, likes_button

ğŸ’¡ Solution:
   - Check GitHub for updates
   - Report issue with diagnostic report
```

---

## ğŸ“ˆ Performance

Tested with real Instagram profiles:

| Profile Size | Time (3 tabs) | Memory | Success Rate |
|--------------|---------------|--------|--------------|
| 100 posts    | ~8 min        | 350 MB | 98-100%      |
| 500 posts    | ~40 min       | 450 MB | 97-99%       |
| 1000 posts   | ~80 min       | 550 MB | 96-98%       |

*Average: 4-5 seconds per post/reel with parallel processing*

---

## ğŸ¤ Contributing

Contributions welcome! Please:

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Test thoroughly
5. Submit a pull request

---

## âš ï¸ Legal & Ethics

**Important:** This tool is for educational and research purposes only.

- âœ… Use on your own account or with permission
- âœ… Respect Instagram's Terms of Service
- âœ… Don't abuse rate limits
- âŒ Don't use for spam or harassment
- âŒ Don't scrape private accounts without permission

**Rate Limiting:** The scraper includes built-in delays to be respectful of Instagram's servers.

---

## ğŸ“ License

MIT License - See [LICENSE](LICENSE) file for details.

---

## ğŸŒŸ Credits

Developed with â¤ï¸ using:
- [Playwright](https://playwright.dev/) - Browser automation
- [BeautifulSoup](https://www.crummy.com/software/BeautifulSoup/) - HTML parsing
- [Pandas](https://pandas.pydata.org/) - Data manipulation

---

## ğŸ“ Support

- **Issues:** [GitHub Issues](https://github.com/yourusername/ArtemInsta/issues)
- **Documentation:** See `PROFESSIONAL_FEATURES.md` (Uzbek)
- **Examples:** See `examples/README.md`

---

## ğŸ¯ Roadmap

- [ ] Support for Stories
- [ ] Support for Comments extraction
- [ ] GUI interface
- [ ] Multiple account support
- [ ] Scheduled scraping

---

**Made with â¤ï¸ for the Instagram scraping community**

â­ **Star this repo if you find it useful!**
