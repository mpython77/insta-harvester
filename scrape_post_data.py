"""
Instagram Post Data Scraper
post_links.txt dan linklar o'qib, har biridan:
- Tagged akkauntlar
- Likes soni
- Post vaqti
"""

import json
import os
import time
from playwright.sync_api import sync_playwright

SESSION_FILE = 'instagram_session.json'
LINKS_FILE = 'post_links.txt'


class InstagramPostDataScraper:
    """Instagram post ma'lumotlarini scraping qilish"""

    def __init__(self):
        self.page = None
        self.context = None
        self.browser = None

    def check_session(self):
        """Session faylni tekshirish"""
        if not os.path.exists(SESSION_FILE):
            raise FileNotFoundError(
                f'‚ùå {SESSION_FILE} topilmadi!\n'
                f'Avval "python save_session.py" ni ishga tushiring.'
            )

    def check_links_file(self):
        """Links faylni tekshirish"""
        if not os.path.exists(LINKS_FILE):
            raise FileNotFoundError(
                f'‚ùå {LINKS_FILE} topilmadi!\n'
                f'Avval "python scrape_post_links.py" ni ishga tushiring.'
            )

    def load_links(self):
        """Linklar faylni o'qish"""
        with open(LINKS_FILE, 'r', encoding='utf-8') as f:
            links = [line.strip() for line in f if line.strip()]
        return links

    def load_session(self, p):
        """Session bilan browser ochish"""
        print('üìÇ Session yuklanmoqda...')

        with open(SESSION_FILE, 'r', encoding='utf-8') as f:
            session_data = json.load(f)

        # Browser ochish
        self.browser = p.chromium.launch(
            headless=False,
            args=['--start-maximized']
        )

        # Session bilan context yaratish
        self.context = self.browser.new_context(
            storage_state=session_data,
            viewport={'width': 1920, 'height': 1080},
            user_agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
        )

        self.page = self.context.new_page()
        self.page.set_default_timeout(60000)

        print('‚úÖ Session yuklandi!')

    def goto_post(self, url):
        """Post sahifasiga o'tish"""
        try:
            self.page.goto(url, wait_until='domcontentloaded', timeout=60000)
            time.sleep(3)  # Sahifa yuklanishi uchun

            # Likes elementini kutish
            try:
                self.page.wait_for_selector('span:has-text("likes")', timeout=5000)
            except Exception:
                pass  # Agar likes bo'lmasa davom etish

            return True
        except Exception as e:
            print(f'‚ö†Ô∏è  Post ochishda xatolik: {e}')
            return False

    def _get_tagged_accounts(self):
        """Tag qilingan akkauntlarni olish"""
        try:
            # ._aa1y class ichidagi barcha a[href] linklar
            tag_containers = self.page.locator('._aa1y').all()

            tagged = []
            for container in tag_containers:
                try:
                    link = container.locator('a[href]').first
                    href = link.get_attribute('href')
                    if href:
                        # Username ni olish (/ larni olib tashlash)
                        username = href.strip('/').split('/')[-1]
                        tagged.append(username)
                except Exception:
                    continue

            return tagged if tagged else ['No tags']
        except Exception as e:
            return ['No tags']

    def _get_likes_count(self):
        """Likes sonini olish"""
        # Method 1: Link orqali (to'g'ri usul - a[href*="/liked_by/"])
        try:
            # <a href="/p/.../liked_by/"> ni topish
            likes_link = self.page.locator('a[href*="/liked_by/"]').first
            # Ichidan span.html-span ni topish
            likes_number = likes_link.locator('span.html-span').first
            likes_text = likes_number.inner_text(timeout=3000)
            # Raqam ekanligini tekshirish
            if likes_text.replace(',', '').isdigit():
                return likes_text.strip().replace(',', '')
        except Exception as e:
            pass

        # Method 2: Section > a[href*="liked_by"] (aniqroq)
        try:
            section = self.page.locator('section').first
            likes_link = section.locator('a[href*="/liked_by/"]').first
            likes_text = likes_link.locator('span.html-span').first.inner_text(timeout=2000)
            if likes_text.replace(',', '').isdigit():
                return likes_text.strip().replace(',', '')
        except Exception:
            pass

        # Method 3: "likes" matni bilan (fallback)
        try:
            # "likes" matnini o'z ichiga olgan span
            likes_count = self.page.locator('span:has-text("likes")').count()

            for i in range(likes_count):
                try:
                    span = self.page.locator('span:has-text("likes")').nth(i)
                    number = span.locator('span.html-span').first
                    text = number.inner_text(timeout=2000)
                    if text.replace(',', '').isdigit():
                        return text.strip().replace(',', '')
                except Exception:
                    continue
        except Exception:
            pass

        # Agar hech narsa topilmasa - likes yashirilgan yoki yo'q
        try:
            page_content = self.page.content()
            if ' likes</span>' in page_content or '>likes<' in page_content:
                return 'N/A'  # Likes bor lekin selector muammosi
            else:
                return 'Hidden'  # Likes yashirilgan
        except Exception:
            pass

        return 'N/A'

    def _get_post_time(self):
        """Post vaqtini olish"""
        try:
            # time elementi
            time_element = self.page.locator('time').first
            if time_element:
                # datetime attribute
                datetime_str = time_element.get_attribute('datetime')
                # title attribute (odam o'qiy oladigan format)
                title_str = time_element.get_attribute('title')

                if title_str:
                    return title_str
                elif datetime_str:
                    return datetime_str
        except Exception:
            pass

        return 'N/A'

    def scrape_post(self, url):
        """Bitta postni scraping qilish"""
        # Postga kirish
        if not self.goto_post(url):
            return None

        # Ma'lumotlar olish
        tagged = self._get_tagged_accounts()
        likes = self._get_likes_count()
        post_time = self._get_post_time()

        return {
            'url': url,
            'tagged_accounts': tagged,
            'likes': likes,
            'post_time': post_time
        }

    def print_post_data(self, data):
        """Post ma'lumotlarini chiroyli formatda chiqarish"""
        if not data:
            return

        print('\n‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ')
        print(f'üîó URL: {data["url"]}')
        print(f'üë• Tagged: {", ".join(data["tagged_accounts"])}')
        print(f'‚ù§Ô∏è  Likes: {data["likes"]}')
        print(f'üïê Time: {data["post_time"]}')
        print('‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ')

    def close(self):
        """Browser yopish"""
        if self.browser:
            self.browser.close()

    def scrape_all(self):
        """Barcha postlarni scraping qilish"""
        self.check_session()
        self.check_links_file()

        # Linklar yuklanmoqda
        links = self.load_links()
        print(f'üìä Jami linklar: {len(links)}\n')

        if not links:
            print('‚ùå Linklar topilmadi!')
            return

        with sync_playwright() as p:
            try:
                self.load_session(p)

                print('üöÄ Scraping boshlandi...\n')

                # Har bir linkni scraping qilish
                for i, link in enumerate(links, 1):
                    print(f'[{i}/{len(links)}] üîç Scraping: {link}')

                    data = self.scrape_post(link)
                    if data:
                        self.print_post_data(data)

                    # Keyingi postga o'tishdan oldin kutish (Instagram limiting)
                    if i < len(links):
                        import random
                        wait_time = random.uniform(2, 4)
                        print(f'‚è≥ {wait_time:.1f}s kutilmoqda...')
                        time.sleep(wait_time)

                print('\n‚úÖ Barcha postlar scraping qilindi!')

            finally:
                time.sleep(2)
                self.close()


def main():
    """Main funksiya"""
    print('üöÄ Instagram Post Data Scraper\n')

    scraper = InstagramPostDataScraper()

    try:
        scraper.scrape_all()
    except Exception as e:
        print(f'\n‚ùå Xatolik: {e}')
        raise


if __name__ == '__main__':
    try:
        main()
    except KeyboardInterrupt:
        print('\n\n‚ö†Ô∏è  Dastur to\'xtatildi!')
    except Exception:
        pass
